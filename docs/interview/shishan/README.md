# 架构笔记

## 并发系列

### volatile

#### 工作内存与主内存

- 每个线程都有自己的工作内存用来存放`变量的副本`。
- `工作内存`相当于一个高速的本地缓存。
- CPU执行代码指令的时候，如果频繁从主内存加载数据，**性能**会比较差。
- 多个线程并发读写一个共享变量的时候，有可能某个线程修改了变量的值，但是其他线程不可见。

#### 作用

1. `volatile`修饰的变量，当本地工作内存修改了值之后，会**强制刷新**结果回主内存，保证主内存和本地内存的数据一致性。
2. 如果此时别的线程的工作内存中有这个变量的本地缓存，会强制让**其他线程**的工作内存中的**变量缓存直接失效过期**，不允许再次读取和使用了。
3. 当另一个线程要读取本地工作内存中被修改过的值，会发现数据已经过期。线程会从主内存中加载变量的最新的值。

#### 总结

- volatile主要作用是保证**可见性**以及**有序性**。
- 有序性涉及到**指令重排**、**内存屏障**等概念。
- volatile不能保证**原子性**。

### Java8对CAS性能的优化

#### 问题场景

- 对于一个变量信息累加的操作，不加锁的正常情况下会出现并发问题。
- 使用`synchronized`的锁量级过重。

#### Atomic原子类的底层原理

- Atomic 原子类底层用的不是传统意义的锁机制，而是无锁化的**CAS机制**，通过 CAS 机制保证多线程修改一个数值的安全性。
- CAS，`Compare and Set`，先比较再进行设置。
- 当如果在执行 CAS 的时候，发现之前获取的值跟当前的值不一样，会导致 CAS 失败，失败之后，进入一个无限循环，再次获取值，接着执行 CAS 操作。

#### Java8对CAS机制的优化

- 在大量线程高并发更新原子类的时候，可能会导致大量线程空循环、自转，**性能和效率**都不是特别好。
- `LongAdder`，通过尝试使用**分段CAS**以及**自动分段迁移**的方式来大幅度提升多线程高并发执行CAS操作的性能。

##### LongAdder

- 在 LongAdder 的底层实现中，首先有个 base 值，刚开始多线程来不停的累加数值，都是对 base 进行累加的。
- 接着如果发现并发更新的线程数量过多，就会开始施行分段 CAS 的机制，也就是内部会搞 Cell 数组，每个数组是一个数值分段。
- 大量的线程分别去对不同 Cell 内部的 value 值进行 CAS 累加操作，这样就把 CAS 计算压力分散到了不同的 Cell 分段数值中，降低了 CAS 计算压力。
- 如果要从 LongAdder 中获取当前累加的总值，就会把 base 值和所有 Cell 分段数值加起来返回给你。
- `自动分段迁移` 如果某个 Cell 的 value 执行 CAS 失败了，那么就会自动去找另外一个 Cell 分段内的 value 值进行 CAS 操作。解決了线程空旋转、自旋不停等待执行 CAS 操作的问题，让一个线程过来执行 CAS 时可以尽快的完成这个操作。

##### 总结

- **高并发中的分段处理机制实际上是一个很常见和常用的并发优化手段。**

------

### Java 锁的一些概念

#### 公平锁

- 在出现多线程竞争锁的情况下，锁的分配严格按照线程请求锁时间的先后依次调度，这样的锁实现，称为公平锁。
- 锁的效率略低。
- 每个新来请求锁资源的线程不会直接进行 CAS 操作去获取锁，而且判断当前等候队列是否存在等待线程。如果存在等待线程，当前线程会直接插入队尾。

#### 非公平锁

- 在出现多线程竞争锁的情况下，请求锁的线程可以直接通过 CAS 操作去申请锁资源，锁的分配不严格按照线程请求锁时间的先后依次调度，这样的锁实现，称为非公平锁。
- 效率高于公平锁。
- 每个新来请求锁资源的线程都会进行 CAS 加锁操作，可能出现插队成功现象，锁的利用率更高。
- **java 并发包中很多锁的默认行为都是非公平锁。**

#### 重入锁

- 当一个线程持有锁的时候，可以访问任意需要该锁的资源和方法。
- ReentrantLock、ReentrantReadWriteLock都是可重入锁的实现。
- 发生锁的重入行为时，`AQS#state`的值 + 1。
- 释放锁的时候，`AQS#state`递减，直到 `state=0`，设置 owner 为 null。

#### 非重入锁

- 锁不可以被任意线程重复持有，获取锁的 CAS 操作的预期 state 值始终为 0。
- 由于不可重入，释放锁的时候，直接设置 `state=0`、`owner=null`。
- `NonReentrantLock` 是不可重入锁的实现。

### AQS 的理解

#### AQS 简介

- Java 高并发的基石。
- 全称 `AbstractQueuedSynchronizer`，抽象队列同步器。
- Java 并发包下很多 API 都是包含了 AQS 的一种实现，都是基于 AQS 实现了加锁、释放锁等功能。
- ReentrantLock、ReentrantReadWriteLock 底层都是基于 AQS。

#### ReentrantLock 底层原理

##### AQS 核心变量

- `state`
  - int 类型。
  - 表示加锁的状态。
  - 初始状态下 state 的值是 0。
- `exclusiveOwnerThread`
  - Thread 类型。
  - 用来记录当前加锁线程是哪个线程。
  - 初始化状态下，这个变量是 null。
- `head`、`tail`
  - 都是 Node 类型。
  - 属性包含 `next` 和 `prev`  指向前一个和后一个 Node 对象。
  - 相当于维护在 AQS 内部的一个等待队列，存储加锁失败的线程。

##### 加锁过程

- 通过 CAS 修改 `AQS#state` 的值为 1。
- CAS 修改成功说明锁未被占用，则更新 `exclusiveOwnerThread` 为当前线程。
- CAS 修改失败说明锁已经被占用，将当前线程封装为 `Node` 添加到等候队列的队尾，并完成线程自挂起`Thread.currentThread().interrupt()`操作。

##### 释放锁过程

- 通过比较 `exclusiveOwnerThread`和当前线程，判断当前线程是否持有当前锁，如果未持有锁，抛出 `IllegalMonitorStateException` 异常。
- 如果当前线程持有锁，`AQS#state` 进行减一操作，当 `AQS#state` 为 0，设置 `exclusiveOwnerThread` 为 null 并唤醒等待队列队列头的线程。
- 释放锁成功，唤醒等候线程队列对头的线程进行 CAS 加锁操作，**如果是非公平锁，此时被唤醒的头部线程未必一定可以获得到锁，可能被外来的线程直接抢到锁**。

------

### 微服务注册中心的读写锁优化

#### 读写锁

- 所谓的读写锁，就是将一个锁拆分为**读锁**和**写锁**两个锁。
- 加锁的时候，可以选择加写锁，也可以选择加读锁。
- **加读锁的操作是不受影响的，可以多个线程同时申请到读锁。**
- 当一个线程加了写锁，那么其他线程就不能加写锁了，**同一时间只能允许一个线程加写锁**。
- **当一个线程加了写锁，其他线程就不能加读锁**。
- **如果任意一个线程加了读锁，此时其他线程是不可以加写锁的**，写入操作需要等待读锁完全被释放。
- **读写锁是非常适合读多写少的场景的。**

#### 服务注册表

- 注册中心会维护一张服务注册表，用来存储服务及服务实例端口、服务地址等数据。
- 由于注册中心的业务场景特点，在内存中的服务注册表天然存在读写并发问题，可能存在同时多线程读、多线程写的问题。

#### 优化流程

##### synchronized

- 简单粗暴的给读写方法都添加上 `synchronized` 关键字。
- 虽然能达到数据的读写安全，但是并发性能很低，并不推荐。

##### 读写锁

- 通过使用读写锁，保证读写业务的安全和高效。
- 服务注册表的业务场景，大部分时候都是读操作，所以使用**读锁**可以让大量的线程同时来读数据，**不需要阻塞不需要排队，保证高并发读的性能是比较高的**。
- 服务注册表的业务场景，**存在少量的写入场景，使用写锁**，保证写入数据过程中，不会存在**并发修改数据**或者**读取数据**的问题。

##### 多级缓存

- 通过**多级缓存**的机制，尽量在写数据的期间还保证可以继续读数据，同时在大量加读锁的时候，降低阻塞写数据加写锁过长时间的情况。

------

### 重要数据的双缓冲区+异步刷盘方案

#### 背景

- 重要核心的业务数据持久化的降级方案。
- 数据正常会以消息的方式发送的 MQ 集群中，由于 MQ 天然的抗高并发性，不需要额外的性能优化设计。
- 为了保证重要的业务数据不丢失，需要对 MQ 集群故障设计一套降级的解决方案。

#### 方案

- 当 MQ 集群故障后，使用**内存双缓冲区+异步刷盘**方案进行业务数据的本地化存储的方案。

- 内存中双缓存区分为 ready 区、current 区。
  - ready 区域中数据是即将要进行刷入本地磁盘文件的数据。
  - current 区域是用来存储来自于当前系统请求中业务数据。
  - ready 区域在每次刷盘后清空内容。
  - 当 current 区域中的数据达到额定容量且 ready 区域为空的时候，交换分区。如果 ready 区域正在进行刷盘操作，不为空时候，系统会挂起后续的写入请求。
- 异步刷盘使用Java NIO 的 API，高性能 append 方式的写入到本地磁盘文件。
- 本地磁盘文件也有自己的文件大小限制、文件新建策略。

#### 流程图

![双缓冲区+异步刷盘](README-image/%E5%8F%8C%E7%BC%93%E5%86%B2%E5%8C%BA+%E5%BC%82%E6%AD%A5%E5%88%B7%E7%9B%98.png)

#### 并发优化

- 双缓冲区的默认值是 512K，可以通过简单的性能测试，
- 线上生产环境出现极高并发的时候，本地刷盘需要一定的时候，导致缓冲区不能释放，大量线程挂起阻塞，造成系统无响应。
- 解决方案是调整缓冲区的大小，从 512K 调整到 10MB。

------



### RabbitMQ 消息生产者的可靠投递

#### 场景

- 消息在投递的过程中，由于网络问题出现丢失。
- 消息被接收后，在消息中间件的内存中没有写入磁盘就产生了宕机。

#### 解决方案

- 生产者端开启 `confirm` 模式，通过 ack 确认消息已经正常的完成投递和持久化，否则根据业务需要进行重新投递。
- 在收到 MQ 回传的 ack 之前，要缓存消息的内容，便于重新投递。
- 开启了`confirm` 模式之后，每次消息投递也同样是有一个 `delivery tag` 的，也是起到**唯一标识一次消息投递**的作用。
- Rabbit MQ接收消息后，如果产生内部错误，会通过 `nack` 通过生产者，生产者根据 nack 返回的内容进行投递失败处理。
- 如果某条消息很长时间都没有回传 `ack/nack`，那可能是极端意外情况发生数据产生丢失，可以进行重新投递。

#### confirm机制投递消息的高延迟性

- 一旦启用了`confirm` 机制投递消息到MQ之后，MQ是不保证什么时候会给你一个 `ack` 或者 `nack` 的。
- RabbitMQ采用异步批量刷盘的方式将消息批量从内存持久化到硬盘的方式兼顾了高并发写入的吞吐量和性能的方案。因此，在开启了 `confirm` 机制后，`ack` 或者 `nack` 消息可能出现延迟。
- 如果采用每条消息都强制刷盘操作的话，会大大降低集群的吞吐量，不建议 `fsync`。

#### 问题分析

##### 消息缓存介质的选择

- 等待 `ack/nack` 期间，缓存的消息不建议使用内存，高并发场景下，可能因为缓存过多的消息而导致内存溢出。
- KV 存储是理想的选择，kV 存储承载高并发能力极强，且 KV 操作性能很高，推荐 Redis 等。

##### 写消息方式的选择

- 绝对不能以**同步写消息 + 等待ack的方式**来投递，那样会导致每次投递一个消息都同步阻塞等待几百毫秒，会导致投递性能和吞吐量大幅度下降。
- **投递消息之后等待 ack 的过程必须是异步的。**消息投递出去之后，投递线程就可以正常返回，每个消息的异步回调，是通过在 `channel` 注册一个 `confirmListener` 实现的。
  - 收到一个消息 ack 后，就从 KV 存储中删除这条临时消息。
  - 收到一个消息 nack 后，就从 KV 存储提取消息重新投递。
  - 通过对 KV 存储里的消息做监控，过滤出超过一定时长没收到 ack的消息，进行主动重发。

#### 消息中间件全链路的数据可靠要点

##### 保证生产端投递出去的消息不丢失

- 避免消息在半路丢失。
- 避免消息在 MQ 内存中因为宕机等原因丢失。
- 结合不同的 MQ 提供的 API 保证数据的可靠性。

##### 保证MQ自身消息不丢失

- 开启持久化功能，将消息写入到磁盘中。
- 使用镜像集群，备份多套消息数据。

##### 保证消费端的消费消息不丢失

- 关闭自动 ack，开始手动 ack 机制。

------

### Java 并发性能优化的一些建议

#### 双缓冲机制

- 解决中间件系统、大数据系统经常需要涉及的场景就是**核心数据写入磁盘**的核心数据缓存问题。
- 在内存中开辟两块空间，向其中一块缓冲器内写数据，当这块缓冲区满额后，后来的写入操作转移到另一块缓冲区。当前缓冲区开始进行异步的刷盘操作。
- 通过两块缓冲区交替缓存、刷盘的工作方式，提供系统的并发性能。
- 假如只用单块缓冲，必然导致读内存数据，刷入磁盘的过程，长时间占用锁。进而导致大量线程卡在锁的获取上，无法获取到锁，然后无法将数据写入内存。这里是经典的用**空间换时间**的解决方案。

#### 内存缓冲区分片机制+分段加锁机制

- 如果写入方法只有一把锁控制的话，会导致所有的写入操作都要串行化，系统的吞吐量会急剧降低。
- 分段锁可以解决串行化严重的问题，**对内存双缓冲机制引入分段加锁机制，也就是将内存缓冲切分为多个分片，每个内存缓冲分片就对应一个锁。**
- **获取缓存分片的方法可以定制负载均衡策略。**

#### 内存 + 磁盘并行写机制

- 缓冲区满了开始进行刷盘操作，如果没有释放锁的话，虽然完成了缓冲区的切换，但是锁没有被释放，其他线程是不能获取锁而进行写入操作。
- **在缓冲区满后，完成切换，要释放当前分片的锁，再由当前线程完成磁盘写入工作。此时磁盘的刷写和内存的写入，完全可以并行同时进行。**
- 并行写入的机制大幅度降低了锁占用的时间，这是 java 并发锁优化的一个非常核心的思路。

### 20W 并发服务热点数据

>热点缓存的架构优化问题。

#### 缓存集群的必要性

- 互联网架构中，往往通过缓存集群来减少对数据库的读压力。

- **缓存集群的并发能力是很强的，而且读缓存的性能是很高。**

#### 处理每秒2w的读写请求

假定每秒 2w 的读写请求中，90%是数据读取，10%是数据写入的场景。

##### 数据库方案

- 分库分表 + 读写分离。
- 三个主库承载每秒 2000 的写入请求。
- 每个主库挂接三个从库，共计 9 个从库承载每秒 1.8w 的读请求。
- 需要合计 12 台 高配置的数据库服务器。

##### 缓存集群方案

- 采用两主两从的缓存集群。
- 主节点用来写入缓存，从节点用来读缓存。
- 两个从节点可以承担每秒 1.8w 的大量读请求。
- 三个数据库主库承担每秒 2000 的写入和少量的读取。
- 合计需要 7 台服务器。

#### 热点缓存的超量访问

- 瞬时超大量的请求访问同一个 key 的缓存数据，可能造成存储对应 key 的缓存服务器崩溃。
- 缓存服务器崩溃后，请求部分来到数据库，数据库查询到数据后，缓存到缓存集群的另一个服务器上，剩余的请求又向新的缓存服务器请求数据，造成新的缓存服务器的崩溃。
- 依次轮转，可能导致整个缓存集群的崩溃。

#### 基于流式计算技术的缓存热点自动发现

- 对于超级热点缓存，系统需要能够在热点缓存突然发生的时候，直接发现他，然后瞬间实现毫秒级的**自动负载均衡**。
- 在请求到达时，可以基于大数据领域的流式计算技术来进行**实时数据访问次数的统计**，`storm`、`spark streaming`、`flink`。
  - **流式计算系统会将请求分布在不同的机器中进行计算，后汇总数据做全局计算，因此不会存在超级并发问题。**
- **通过实际数据访问次数计算，根据业务情况发现超级热点数据，并将热点数据记录下**，比如记录在  `zookeeper` 中。

#### 热点缓存自动加载为JVM本地缓存

- 业务系统通过对 `zookeeper` 指定的热点缓存对应的 `znode` 进行监听，会感知到热点数据的产生。
- 此时业务系统将要缓存数据从数据库中加载出来，放在**系统内部的本地缓存**里即可。
  - 本地缓存使用 `ehcache`、`hashmap`都可以。
  - 只要就是从缓存集群中，升级为系统的本地缓存即可。
- 需要评估好热点数据，系统的本地缓存是不能存储过多数据的。

#### 限流熔断保护

- 业务系统内部，需要对热点数据访问添加一个限流熔断保护措施。
- 一单请求超过设定的阈值，就开启熔断策略，返回空白页，保护后端的缓存集群和数据库。

####  图示

![缓存方案](README-image/%E7%BC%93%E5%AD%98%E6%96%B9%E6%A1%88.png)

------

### 日活百万系统的数据库设计

#### 服务器并发能力

- 16 核 32 G的数据库服务器，每秒请求支撑不要超过 2000。

#### 分库

- 多个服务器的数据库实例下创建相同的库。
- 写入数据的时候借助于 `sharding-jdbc`、`mycat` 中间件。
- 根据业务规则进行数据的分库存储，比如订单 ID 的 hash 后根据库的数量进行取模。
- 通过 ID 来查询的时候，同样根据 ID 的 hash 进行取模锁定要查询的库。

#### 分表

- 通过分表，大量分表，解决分库后单表数据依然过大的问题。
- 此时写入分表的数据需要经过两次路由才能锁定具体的数据库的具体的表中。
- 大量分表的策略保证可能未来10年，每个表的数据量都不会太大，这可以保证单表内的SQL执行效率和性能。

#### 读写分离

- 通过数据库的主从模式，实现读写分离。
- 写入主库的时候，会自动同步数据到从库上去，保证主库和从库数据一致，查询的时候都是走从库去查询。
- 生产中，大部分的还是读请求，通过扩容从库，可以达到支持更多的读请求。
- 对同一个表，如果你既写入数据（涉及加锁），还从该表查询数据，可能会牵扯到锁冲突等问题，无论是写性能还是读性能，都会有影响。

#### 总结

- 大量分表保证每个表的数据量别太大，读写分离实现主库和从库按需扩容以及性能保证。

------

### 百万连接的系统架构设计

#### 长连接

- 系统建立连接后，连接长期持有，多次请求无需花费额外的开销进行连接创建。
- 可以提供更快的响应速度。

#### 线程资源的浪费

- 根据线上的生产经验，一般4核8G的标准服务用的虚拟机，自己开辟的工作线程在**一两百**个就会让CPU负载很高了，**最佳的建议就是在几十个工作线程就差不多**。
- 期望每个服务实例来维持上万个线程，那几乎是不可能的。

#### Reactor 多路复用

-  **Reactor 多路复用**模型是支持高并发的常用架构策略，kafka 等中间件就使用该策略。
- 多路复用体系中包含 `acceptor` 线程，基于底层操作系统的支持，实现连接请求监听。
- 如果有某个设备发送了建立连接的请求过来，那么那个线程就把这个建立好的连接交给 `processor` 线程。
- 每个 `processor` 线程会被分配N多个连接，**一个线程就可以负责维持N多个连接**，基于底层操作系统的特殊机制的支持监听N多连接的请求，可以让一个线程支持多个连接了，不需要一个连接一个线程来支持。
- `processor` 线程仅仅是接收请求和发送响应。所有的请求都会入队列排队，交给后台线程池来处理。
- **工作线程池里的线程会从请求队列里获取请求，处理请求，接着将请求对应的响应放到每个 processor 线程对应的一个响应队列里去。**
- **processor 线程会把自己的响应队列里的响应发送回给客户端**。

![多路复用机制](README-image/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E6%9C%BA%E5%88%B6.png)

------

## 微服务

### Spring Cloud 底层原理

#### Eureka

- `Eureka` 是微服务架构中的注册中心，专门负责服务的注册与发现。
- `Eureka Client` 会在服务启动的时候，将服务的地址、端口、名称等信息发送到 `Eureka Server`。
- `Eureka Server`  收集服务发送过来的注册信息，完成注册、维护服务器端的注册表。
- 每个 `Eureka Client`  客户端本地缓存一份注册表信息，保存了各个服务所在的机器和端口号。

#### Feign

- `Feign` 是一套远程调用组件，完成服务的远程调用。
- **Feign的一个关键机制就是使用了动态代理**。
- 在某个接口定义了 `@FeignClient` 注解，Feign就会针对这个接口创建一个动态代理。
- Feign 的动态代理会根据你在接口上的 `@RequestMapping` 等注解，来动态构造出你要请求的服务的地址。
- Feign 根据方法的参数、返回值在方法被调用的时候完成发起请求、解析响应。

#### Ribbon

- `Ribbon` 的作用是**负载均衡**，会帮你在每次请求时选择一台机器，均匀的把请求分发到各个机器上。
- `Ribbon` 的负载均衡默认使用的最经典的 `Round Robin 轮询算法`，将请求依次分配到每个服务器。
- `Ribbon` 是和 `Feign` 以及 `Eureka` 紧密协作，完成工作的。
  - `Ribbon` 会从 `Eureka Client` 里获取到对应的服务注册表，也就知道了所有的服务都部署在了哪些机器上，在监听哪些端口号。
  - `Ribbon` 就可以使用默认的 `Round Robin` 算法，从中选择一台机器。
  - `Feign` 就会针对这台机器，构造并发起请求。

#### Hystrix

- `Hystrix` 是隔离、熔断以及降级的一个框架。
- `Hystrix` 会维护很多个小小的线程池，发起请求是通过 `Hystrix` 的线程池来走的，**不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题**。
- **服务降级的时候，执行降级逻辑，往本地服务数据库中或者日志中记录必要的业务信息，等待服务回复后，恢复数据。**

#### Zuul

- `Zuul` 是微服务网关，**负责网络路由**。
- **所有请求都往网关走，网关会根据请求中的一些特征，将请求转发给后端的各个服务。**
- 有了网关之后，可以做**统一的降级、限流、认证授权、安全**。

------

### Eureka 如何承载每日千万级访问

#### Eureka 的服务注册与心跳管理

- 各个服务内的 `Eureka Client` 组件默认是**每隔 30 秒**向  `Eureka Server` 获取最新的服务器应用列表信息。
- Eureka 的心跳机制，各个 `Eureka Client` **每隔 30 秒**会发送一次心跳到 **Eureka Server**。
- 日请求在千万级访问量的情况下，实际上 `Eureka Server` 每秒钟承载的请求大概在 200~300 次。
- 通过设置一个适当的拉取注册表以及发送心跳的频率，可以保证大规模系统里对 `Eureka Server` 的请求压力不会太大。

#### 服务端注册表存储结构

- `Eureka Server` 存储注册信息的容器选择的是 `CocurrentHashMap`。
- 注册表直接基于**纯内存**，即在内存里维护了一个数据结构。
- 各个服务的注册、服务下线、服务故障，全部会在内存里维护和更新这个注册表。
- 各个服务每隔 30 秒拉取注册表的时候，`Eureka Server` 就是直接提供内存里存储的**有变化的注册表数据**。
- **维护注册表**、**拉取注册表**、**更新心跳时间**，全部发生在内存里。这是 `Eureka Server` 非常核心的一个点。
- 注册表的结构 `CocurrentHashMap<String, Map<String, Lease<InstanceInfo>>>`。
  - `CocurrentHashMap` 的 `key` 是服务的名称。
  - `CocurrentHashMap` 的 `value` 是服务的多个实例。
  - `Map<String, Lease<InstanceInfo>>` 的 `key` 是**服务实例的id**。
  - `Map<String, Lease<InstanceInfo>>` 的 `value` 是 `Lease类`，泛型是 `InstanceInfo`。
    - `Lease` 维护每个服务器最近一次的心跳时间。
    - `InstanceInfo` 存储服务实例的具体信息。

#### 服务端多级缓存机制

- 假设 Eureka Server 部署在 4 核 8G 的普通机器上，**基于内存来承载各个服务的请求**，每秒可以轻松的处理几百请求。
- `Eureka Server` 为了**避免同时读写内存数据结构造成的并发冲突问题**，采用**多级缓存机制**来进一步提升服务请求的响应速度。
- **拉取注册表**
  - 首先从 `ReadOnlyCacheMap` 里查缓存的注册表。
  - 若没有，就找 `ReadWriteCacheMap` 里缓存的注册表。
  - 如果还没有，就从**内存中获取实际的注册表数据。**
- **修改注册表**
  - 在内存中更新变更的注册表数据，同时**过期掉ReadWriteCacheMap**。
  - 此过程不会影响 `ReadOnlyCacheMap` 提供查询注册表功能。
  - 一段时间内（默认30秒），各服务拉取注册表会直接读 `ReadOnlyCacheMap`。
  - 30秒过后，`Eureka Server` 的后台线程发现 `ReadWriteCacheMap` 已经清空了，也会清空  `ReadOnlyCacheMap` 中的缓存。
  - 下次有服务拉取注册表，又会从内存中获取最新的数据了，同时填充各个缓存。

#### 多级缓存机制的优点

- **尽可能保证了内存注册表数据不会出现频繁的读写冲突问题。**
- **进一步保证对 Eureka Server 的大量请求，都是快速从纯内存走，性能极高。**

![Eureka多级缓存注册表](README-image/Eureka%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98%E6%B3%A8%E5%86%8C%E8%A1%A8.png)

------

### 每秒上万并发下的 Spring Cloud 参数优化实战

#### 问题成因

- 核心业务由于慢 SQL 导致的响应超时问题，没有通过优化 SQL 的方式去解决，调整了 `Ribbon` 和 `Hystrix`的超时参数，让系统带病运行。
- 当数据库单表数据量增加后，请求个别问题 SQL 超时时间过长，`Hystrix` 的线程池被占用耗尽，导致对应服务整体都不可被访问。

#### 优化思路

- 优化核心服务性能，解决Hystrix 线程池频繁卡死的情况。
- 面向 C 端用户高并发的请求不要大 SQL、多表关联或者单表几百万行数据。
- 对数据库就执行简单的单表查询和更新，复杂的业务逻辑全部放到 Java 系统中处理，比如关联、计算。
- 调整超时时间，不要不优化系统，单单放开超时时间来保证系统可响应，一般超时定义在1秒以内，是比较通用以及合理的。 
- 配合着超时时间，一般都会设置一个合理的重试，避免偶尔的网络波动导致的请求超时。
- **只要涉及到了重试，那么必须上接口的幂等性保障机制**。

------

### 保障双 11 狂欢下的 99.99% 高可用

#### 问题场景

- 系统出现不可用的情况可能是出现一些基础设施的故障、redis 集群宕机、es 集群故障等。
- 微服务架构本身**最最核心**的保障高可用的措施。
  - **基于Hystrix做资源隔离以及熔断。**
  - **做备用降级方案。**
- 如果资源隔离和降级都做的很完善，高并发下，也许可能会出现个别的服务故障，但是绝不会蔓延到整个系统全部宕机。

#### 解决方案

- **要保证一个 hystrix 线程池可以轻松处理每秒钟的请求**。
- hystrix 资源隔离以及超时的设置，必须合理，避免高峰期，频繁的hystrix线程卡死。
- **合理的超时时间设置，避免请求太慢卡死线程**。
- 针对个别的服务故障，要设置合理的降级策略，保证各个服务挂了，可以合理的降级，系统整体可用。

#### 实际案例

- 假设服务A，每秒钟会接收 30 个请求，同时会向服务B发起 30 个请求，然后每个请求的响应时长经验值大概在 200ms。

- **线程数计算公式**

  `30（每秒请求数量） *  0.2（每个请求的处理秒数）+ 4（给点缓冲buffer） = 10（线程数量）`

- 结合响应时长 200ms 的经验平均值，请求的超时时间设置为 300 毫秒，保证一个请求300毫秒内执行不完，立马超时返回。
- 线程池里的线程不会长时间卡死，可以有条不紊的处理多出来的请求，大不了就是 300 毫秒内处理不完立即超时返回，但是线程始终保持可以运行的状态。

#### 降级策略

- 某个服务挂了，`hystrix` 会走熔断器，然后就会降级，需要考虑到各个服务的**降级逻辑**。
- 具体用什么降级策略，要根据业务来定，不是一成不变的。
- 常见的降级策略。
  - 如果查询数据的服务挂了，可以查本地的缓存。
  - 如果写入数据的服务挂了，可以先把这个写入操作记录日志到 mysql 或者写入 MQ 里，后面再慢慢恢复。
  - 如果 redis 挂了，你可以查 mysql。
  - 如果 mysql 挂了，可以把操作日志记录到 es 里去，后面再慢慢恢复数据。

------

### Consul 微服务注册中心

#### 简介

- 必须在每个服务所在的机器上部署一个 `Consul Agent`，作为一个服务所在机器的代理。
- 在多台机器上部署 `Consul Server`，这就是核心的服务注册中心，一般要求 3~5 台，保证高可用及数据一致性。
- `Consul Server` 之间会自动实现数据同步，而且 `Consul Server` 集群会自动选举出一台机器作为 **leader**，其他的 `Consul Server` 就是 **follower**。
- `Consul Agent` 可以用来收集你的服务信息然后发送给 `Consul Server`，还会对服务不停的发送请求检查他是否健康。

#### Raft 的强一致性策略

- `Eureka` 服务注册中心是不保证数据一致性的，`Consul` 是数据强一致性的。
- 各个服务发送的注册请求都会落地给 **Leader**，由 **Leader** 同步给其他 **Follower**，`Leader Server` 是绝对有最新的服务注册信息。
- 查询请求会发送给 `Leader Server`，**服务注册和发现，都是通过一台 `Leader Server` 来进行的，就可以保证服务注册数据的强一致性**。
- 如果注册的过程中 `Leader Server` 发生宕机，**Consul会基于Raft协议来解决这个问题**。
  - **注册服务到 `Leader Server` 的时候，会采取 Raft 协议，要求必须让 Leader Server 把这条注册数据复制给大部分的 Follower Server 才算成功。**
  - 如果注册信息刚发送给 Leader Server 他自己就宕机了，那么这次注册会认为**失败**，这种情况 Consul Server 集群会重新选举一个 `Leader Server` 出来，**需要再次重新注册**。
  - Raft 保证注册成功的数据绝对不会丢，然后其他服务发现服务的时候一定可以从 Leader Server上获取到最新的强一致的注册数据。

#### 分布式健康检查

- 集中式的心跳机制，比如传统的 Eureka，是让各个服务都必须每隔一定时间发送心跳到 Eureka Server。
- 集中式的心跳检测会对集中的服务器造成请求压力。
- 每个机器上的 `Consul Agent` 会不断的发送请求检查服务是否健康，是否宕机。**如果服务宕机了，那么就会通知 Consul Server。**
- Consul 基于 Agent 实现的**分布式健康检查机制**，可以大幅度的减小 Server 端的压力。

------

## 分布式

### TCC分布式事务

#### TCC 的阶段一 Try 

- 首先业务的主流程以及各个接口提供的业务含义，不是说直接完成那个业务操作，**而是完成一个 Try 的操作**。
- 更新到一个中间状态，一般都是锁定某个资源，设置一个预备类的状态，冻结部分数据。

#### TCC 的阶段二 Commit

- 如果各个第一阶段的尝试操作都成功了，那么进入到 TCC 的第二阶段。
- 第二阶段 Commit 阶段，提交对业务数据的正式修改。

####  TCC 的阶段三 Cancel

- 如果在 Try 阶段出现报错，会进入到 Cancel 阶段，进行数据回滚。

#### TCC 总结

- **首先需要选择某种TCC分布式事务框架**，各个服务里就会有这个TCC分布式事务框架在运行。
- **原本的一个接口，要改造为 3 个逻辑，Try-Confirm-Cancel**。
- 如果都正常的话，TCC 分布式事务框架推进执行 Confirm 逻辑，完成整个事务。
- 如果某个服务的 Try 逻辑有问题，TCC分布式事务框架感知到之后就会推进执行各个服务的 Cancel 逻辑，撤销之前执行的各种操作。

- 避免系统出现某个服务的数据库宕机、服务宕机、redis、es、mq 等基础设施故障、资源不足的情况，TCC分布式事务的思想是先来 Try 一下，不要把业务逻辑完成，先试试看，看各个服务能不能基本正常运转，能不能先冻结需要的资源。
- TCC事务框架都是要记录一些分布式事务的活动日志的，可以在磁盘上的日志文件里记录，也可以在数据库里记录。保存下来分布式事务运行的各个阶段和状态。

------

### 基于可靠消息的最终一致性分布式事务

#### 简述

- 虽然 TCC 框架能保证分布式事务的强一致性，在实际系统的开发过程中，可能服务间的调用是异步的。
- 异步的调用一般基于 MQ 消息，实现**可靠消息最终一致性方案**。
- 如果不考虑各种高并发、高可用等技术挑战的话，单从**可靠消息**以及**最终一致性**两个角度来考虑，这种分布式事务方案还是比较简单的。

#### 核心流程

**如果要实现可靠消息最终一致性方案，需要编写一个可靠消息服务，实现一些业务逻辑。**

1. 上游服务投递消息。
   - 上游服务发送消息给可靠消息服务，消息包含必要的业务信息。
   - 可靠消息服务就得把这条消息存储到自己的数据库里去，状态为**待确认**。
   - 上游服务就可以执行自己本地的数据库操作，根据自己的执行结果，再次调用可靠消息服务的接口。
     - 如果本地数据库操作执行成功，那么就找可靠消息服务确认那条消息。
     - 如果本地数据库操作失败，那么就找可靠消息服务删除那条消息。
   - 此时如果是确认消息，那么可靠消息服务就把数据库里的消息状态更新为**已发送**，同时将消息发送给 MQ，更新数据库里的消息状态和投递消息到MQ的操作要在同一个事务中。
   - 如果上游服务是通知删除消息，那么可靠消息服务就得删除这条消息。
2. 下游服务接收消息。
   - 下游服务就一直等着从MQ消费消息，如果消费到了消息，那么就操作自己本地数据库。
   - 如果操作成功，就反过来通知可靠消息服务，说自己处理成功，然后可靠消息服务就会把消息的状态设置为**已完成**。
3. 上游服务对消息的100%可靠投递。
   - 发送**待确定**消息报错，上游服务可以感知，可以正常重试。
   - 可靠消息服务通过回调接口，回查上游服务的状态，对长期处于待确认状态的消息，进行回调状态确认。
     - 如果上对上游服务的回调查询状态，上游服务处理成功，投递本条消息并修改状态为已发送。
     - 如果上对上游服务的回调查询状态，上游服务处理失败，删除本条消息。
4. 下游服务对消息的100%可靠接收。
   - 在可靠消息服务里开发一个后台线程，不断的检查消息状态，对于已经发送但是长期没有处理完成的消息进行状态检查。
   - 对于长时间没有变更状态的消息可靠消息服务就可以再次尝试重新投递消息到MQ，让下游服务来再次处理。
   - **下游服务的接口逻辑实现幂等性，保证多次处理一个消息，不会插入重复数据即可。**

#### RocketMQ 事务消息

- 在上面的通用方案设计里，完全依赖可靠消息服务的各种自检机制来确保。
  - 如果上游服务的数据库操作没成功，下游服务是不会收到任何通知。
  - 如果上游服务的数据库操作成功了，可靠消息服务会确保将一个调用消息投递给下游服务，而且一定会确保下游服务务必成功处理这条消息。
- RocketMQ，实现了可靠消息服务的所有功能，核心思想类似。
- 通过 RocketMQ 的事务消息、消息重试、手动 ack 确保等机制消息的可靠性和分布式事务的最终一致性。

#### 生产实践

- 任何一种 MQ 中间件都有一整套的高可用保障机制，但是为了避免中间件集群宕机带来的问题，也要制定出一套降级方案。
- 基于KV存储的队列支持的高可用降级方案，自封组件需要涵盖如下功能。
  - 自行封装MQ客户端组件与故障感知。
  - 触发降级后使用基于kv存储中队列消息。
    - 任何 kv 存储的集合类数据结构，建议不要往里面写入数据量过大。
    - 避免热点 key 的产生导致热点问题。
  - 下游服务消费MQ的降级感知。
  - 探测故障的自动恢复。

------

### Redisson分布式锁的底层原理

#### 加锁机制

- 如果客户端面对的是一个 redis cluster 集群，他首先会根据 hash 节点选择一台机器。
- 发送一段复杂的 lua 脚本到 redis 上，进行尝试加锁操作，lua 脚本保证业务逻辑执行的**原子性**。

#### lua 加锁代码解析

- `KEYS[1]` 代表的是要加锁的那个 key。
- `ARGV[1]` 代表的就是锁 key 的默认生存时间，默认 30 秒。
- `ARGV[2]` 代表的是加锁的客户端的ID，类似于 8743c9c0-0795-4907-87fd-6c719a6b4586:1。
- 第一段 if 判断语句，用 `exists` 命令判断一下，如果要加锁的那个锁 key 不存在的话，进行加锁。
- 通过 `hincrby` 命令调用 `hset` 设置一个 hash 数据结构。
- 通过 `pexpire` 命令设置锁的生存时间。

```shell
// 如果不存在加锁的key(serviceKey)就执行加锁的逻辑
"if (redis.call('exists', KEYS[1]) == 0) then " +
    // hincrby命令：给指定Hash类型Key对应的Map结构的，key对应的value值进行+1
    "redis.call('hincrby', KEYS[1], ARGV[2], 1); " +
    // pexpire命令：给指定的Key设置过期时间
    "redis.call('pexpire', KEYS[1], ARGV[1]); " +
    "return nil; " +
    "end; " +
    // 判断Hash类型的加锁的key对应的的Map结构中，key对应的value是否存在
"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then " +
    // 将key对应的value值进行+1
    "redis.call('hincrby', KEYS[1], ARGV[2], 1); " +
    // pexpire命令：给指定的Key设置过期时间
    "redis.call('pexpire', KEYS[1], ARGV[1]); " +
     "return nil; " +
     "end; " +
    // 返回Key(serviceKey)的过期时间
"return redis.call('pttl', KEYS[1]);",
```

#### 锁互斥机制

- 如果客户端2来尝试加锁，执行了同样的一段lua脚本。
- 第一个 if 判断会执行 `exists`，发现锁 key 已经存在了。
- 第二个 if 判断，判断一下，锁 key 的 hash 数据结构中，是否包含客户端 2 的 ID，但是明显不是的，因为那里包含的是客户端 1 的 ID。
- 客户端2会获取到 `pttl` 返回的一个数字，这个数字代表了锁 key 的**剩余生存时间。**
- 此时客户端 2 会进入一个 `while` 循环，不停的尝试加锁。

#### watch dog 自动延期机制

- 只要客户端一旦加锁成功，就会启动一个 `watch dog` 看门狗。
- **看门狗是一个后台线程，会每隔10秒检查一下**。如果客户端还持有锁 key，那么就会不断的延长锁 key 的生存时间。

#### 可重入加锁机制

- 第一个 if 判断肯定不成立，`exists` 会显示锁 key 已经存在了。
- 第二个 if 判断会成立，因为锁的 hash 数据结构中包含的ID，就是当前客户端的ID。
- 此时就会执行可重入加锁的逻辑。
- 通过 调用 `incrby` 命令，给当前客户端增加加锁的次数。

```json
lock: {
  "888xcz-qa5425-sasd4q-cccx:1":2
}
```

#### 释放锁机制

- 释放分布式锁，每次都对锁的数据结构中的那个加锁次数减 1。
- 如果发现加锁次数是 0 了，说明这个客户端已经不再持有锁。
- 通过调用 `del` 命令，从 redis 里删除这个 key。

#### 缺点

- `redis cluster` 或者是 `redis master-slave` 架构的**主从异步复制**导致的 redis 分布式锁的最大缺陷，在 `redis master` 实例宕机的时候，可能导致多个客户端同时完成加锁。

------

### 分布式锁高并发优化实践

#### 防止库存超卖的解决方案

- 悲观锁。
- 分布式锁。
- 乐观锁。
- 队列串行化。
- Redis 原子操作。

#### 分布式锁优化

- 分布式锁一旦加了之后，对同一个商品的下单请求，会导致所有客户端都必须对同一个商品的库存锁 key 进行加锁。
- 分布式锁保证了数据的准确性，但是天然并发能力有点弱。
- 使用分布式锁会导致所有客户端都必须对同一个锁 key 进行加锁，导致请求串行化。优化的核心思路，就是**分段加锁**。
- 分段锁的思路参考 `LongAdder` 和 `ConcurrentHashMap`，通过分段加锁的方式，解决的是CAS类操作在高并发场景下，使用乐观锁思路，会导致大量线程长时间重复循环。
- 分段CAS操作，失败则自动迁移到下一个分段进行CAS。

#### 重点实现

- 如果加锁过程中发现资源不足，需要自动释放锁，立即换下一个分段资源，再次尝试加锁后尝试处理。

#### 方案缺陷

- 实现方案过于复杂，资源需要进行分段管理。
- 每次处理分段资源请求需要通过随机算法，随机挑选分段。
- 某个分段中的数据不足，需要自动切换到下一个分段数据去处理。

------

### Zookeeper分布式锁原理

`Curator` 框架对 Zookeeper 客户端进行封装，提供了基于 Zookeeper 的分布式锁实现。

#### 分布式锁实现

- 加锁请求是用到 Zookeeper 中的一个特殊的概念，叫做`临时顺序节点`。

- 顺序节点有 Zookeeper 内部自行维护的一个节点序号，**最后一个数字都是依次递增的**，从1开始逐次递增。Zookeeper 会维护这个顺序。

- Curator 创建的节点数据示例，加锁请求会**在要加锁的 node 下搞一个临时顺序节点**，长长的名字都是 Curator 框架自己生成出来的。

  ```xml
  - mylock
  	- _xasd1254-asda-324asd-asd-lock-00000001 
  ```

- 创建完一个顺序节点，客户端需要检查锁节点下所有子节点。

- 获取所有的子节点后，客户端判断是否自己创建的顺序节点排在第一个。

  - 如果是的话，说明分布式锁添加成功，开始执行加锁业务。
  - 如果不是的话，说明分布式锁添加失败，客户端会通过 Zookeeper 的 api 在上一个顺序节点上添加一个监听器，等到上一个节点的数据发生变化（即锁释放节点被删除），重新判断自己是否获取到锁。

- 锁释放的过程就是将自己在 Zookeeper 中创建的顺序节点删除，如果该顺序节点上有注册的监听器，同时调用监听器进行回调。

#### 总结

- 使用 `临时顺序节点` 是为了解决系统出现意外情况，锁不能正常释放，**当 Zookeeper 感知到对应的客户端发生宕机，会自动删除对应的临时顺序节点**。
- 自动删除节点相当于**释放锁**或者**取消排队**。

#### 图例

![Zookeeper 分布式锁原理](README-image/Zookeeper%20%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%8E%9F%E7%90%86.jpg)

------

### 分布式存储系统容错架构

#### 简介

- 分布式存储系统指的是将超大的数据存储进行分片分段存储在各个服务器的系统。
- 分布式存储为了保证数据的完整性和集群的可用性往往会对分片备份多个副本。

#### 基础能力

- 数据分片存储。
- 多副本冗余。
- 宕机感知。
- 自动副本迁移。
- 多余副本删除。

#### 系统设计

- 从架构层面来看，分布式存储系统，应该有两种进程。
- Master 节点。
  - 负责统一管控分散在多台机器上的数据。
  - 通过监控 Slave 的心跳来确定副本是否丢失，当确定副本丢失后，Master 不会在从对应节点读取数据，并且会根据丢失的数据创建新的副本到其他 Slave。
  - 当副本数量不足时，需要自动进行副本迁移产生新的副本，当宕机的 Slave 恢复后，会自动将多余的副本进行删除。
- Slave 节点。
  - 负责管理那台机器上的数据。
  - 负责和 Master 节点进行通信。

- 数据分片需要以**多副本**的方式存放在多个 Slave 节点，避免因为部分节点宕机、损坏造成的数据丢失。
- 优秀的数据备份算法是分布式存储系统至关重要的一环。

------

### Elasticsearch架构原理

#### 倒排索引

- 所谓的倒排索引，就是把数据内容先分词，每句话分成一个一个的关键词，记录好每个关键词对应出现在了哪些 id 标识的数据里。
- 进行关键字检索的时候，会直接扫描这个倒排索引，在倒排索引里找到关键词对应的那些数据的 id。
- **分词器**和**词库**的结果影响搜索引擎的检索效果。
- 利用倒排索引查找数据的方式，也被称之为**全文检索**。

#### 分布式搜索引擎

- 分布式搜索引擎的核心是分布式，每个节点存储着部分的数据分片。
- 进行数据检索时，每个节点都进行检索任务，最后将数据汇总、返回。
- 通过分布式检索，大大地提高了响应速度。
- 每个节点的分片数据也会有副本备份，避免某个子节点宕机导致的数据丢失。

#### Elasticsearch 的数据结构

- `index` 索引，有点类似于数据库里的一张表，大概对应表的那个概念。
- `document` 文档，就代表了 index 中的一条数据。

#### Shard 数据分片机制

- **Shard 数据分片结构**。
- 每个 index 都可以指定创建多少个 `shard`，每个 shard 就是一个**数据分片**，会负责存储这个 index 的**一部分数据**。

#### Replica 多副本数据冗余机制

- 为了实现高可用使用 Replica 多副本数据冗余机制。
- 在 Elasticsearch 里，就是支持对每个index设置一个 replica 数量的，也就是每个 shard 对应的 replica 副本的数量。
- 初始的 shard 就是 `primary shard`，副本的 shard 是 `replica shard`，`primary shard` 和 `replica shard` 是绝对不会放在一台机器上的，避免一台机器宕机直接一个 shard 的副本也同时丢失。 
- Elasticsearch 默认是支持每个 index 是 5 个 primary shard，每个 primary shard 有 1 个 replica shard 作为副本。

------

### 分布式系统的唯一id生成算法

#### 独立数据库自增id

- 通过独立库的一个独立表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个 id。
- 拿到这个 id 之后再往对应的分库分表里去写入。
- 利用数据库自增 id 的方案实现简单，缺点就是在高并发场景下，会有性能瓶颈。

#### UUID

- 使用 UUID 的好处是每个系统本地生成，不用依赖与数据库。
- 缺点是 UUID 过长，而且作为主键性能很差，不适合做主键。
- 建议 UUID 可以用来做随机的文件名。

#### 系统当前时间

- 获取当前时间作为全局唯一的 id。
- 方案的缺陷很明显，高并发场景会出现重复的情况。
- 如果使用这个方案，推荐是将**当前时间跟很多其他的业务字段拼接起来**，满足业务场景，即可。
- 可以使用 `时间戳 + 用户id + 业务含义编码` 的方案作为订单编号。

#### snowflake算法的思想分析

- snowflake 算法，也叫雪花算法，是 twitter 开源的分布式id生成算法。
- 其核心思想就是使用一个 64 bit 的 long 型的数字作为全局唯一 id。
  - 第 1 位 bit 是不用的，因为二进制里第一个 bit 如果是 1 的话，表示的是负数。
  - 第 2 位 ~ 第 42 位是 时间戳，单位是毫秒。
  - 第 43 位 ~ 第 47 位是机房 id，代表的是这个服务最多可以部署在 2^10 台机器上，也就是 1024 台机器，存在机房 32 个。
  - 第 48 位 ~ 第 52 位 位表示机器 id，每个机房里可以代表 $2 ^ 5$ 个机器，32 台机器。
  - 第 53 位 ~ 第 64 位 bit 作为序列号，就是某个机房某台机器上这一毫秒内同时生成的 id 的序号，$2 ^{12} - 1 = 4096$，就是说可以用这个 12 bit 代表的数字来区分同一个毫秒内的 4096 个不同的id。
- snowflake 算法的系统根据请求的机器的机房 id、机器 id和是当前毫秒的第 n 个请求为条件，创建一个唯一的 id 并返回。
- **总之雪花算法的思想就是用一个 64bit 的数字中各个 bit 位来设置不同的标志位，区分每一个 id。**

#### 雪花算法实现代码

```java
public class IdWorker {

   private long workerId; // 这个就是代表了机器id
   private long datacenterId; // 这个就是代表了机房id
   private long sequence; // 这个就是代表了一毫秒内生成的多个id的最新序号

   public IdWorker(long workerId, long datacenterId, long sequence) {

       // sanity check for workerId
       // 这儿不就检查了一下，要求就是你传递进来的机房id和机器id不能超过32，不能小于0
       if (workerId > maxWorkerId || workerId < 0) {
           
           throw new IllegalArgumentException(
               String.format("worker Id can't be greater than %d or less than 0",maxWorkerId));
       }
       
       if (datacenterId > maxDatacenterId || datacenterId < 0) {
       
           throw new IllegalArgumentException(
               String.format("datacenter Id can't be greater than %d or less than 0",maxDatacenterId));
       }

       this.workerId = workerId;
       this.datacenterId = datacenterId;
       this.sequence = sequence;
   }

   private long twepoch = 1288834974657L;

   private long workerIdBits = 5L;
   private long datacenterIdBits = 5L;
   
   // 这个是二进制运算，就是5 bit最多只能有31个数字，也就是说机器id最多只能是32以内
   private long maxWorkerId = -1L ^ (-1L << workerIdBits);

   // 这个是一个意思，就是5 bit最多只能有31个数字，机房id最多只能是32以内
   private long maxDatacenterId = -1L ^ (-1L << datacenterIdBits);
   private long sequenceBits = 12L;

   private long workerIdShift = sequenceBits;
   private long datacenterIdShift = sequenceBits + workerIdBits;
   private long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;
   private long sequenceMask = -1L ^ (-1L << sequenceBits);

   private long lastTimestamp = -1L;

   public long getWorkerId(){
       return workerId;
   }

   public long getDatacenterId() {
       return datacenterId;
   }

   public long getTimestamp() {
       return System.currentTimeMillis();
   }

   // 这个是核心方法，通过调用nextId()方法，让当前这台机器上的snowflake算法程序生成一个全局唯一的id
   public synchronized long nextId() {

       // 这儿就是获取当前时间戳，单位是毫秒
       long timestamp = timeGen();

       if (timestamp < lastTimestamp) {
           System.err.printf(
               "clock is moving backwards. Rejecting requests until %d.", lastTimestamp);
           throw new RuntimeException(
               String.format("Clock moved backwards. Refusing to generate id for %d milliseconds",
                             lastTimestamp - timestamp));
       }

       
       // 下面是说假设在同一个毫秒内，又发送了一个请求生成一个id
       // 这个时候就得把seqence序号给递增1，最多就是4096
       if (lastTimestamp == timestamp) {
       
           // 这个意思是说一个毫秒内最多只能有4096个数字，无论你传递多少进来，
           //这个位运算保证始终就是在4096这个范围内，避免你自己传递个sequence超过了4096这个范围
           sequence = (sequence + 1) & sequenceMask;

           if (sequence == 0) {
               timestamp = tilNextMillis(lastTimestamp);
           }
       
       } else {
           sequence = 0;
       }

       // 这儿记录一下最近一次生成id的时间戳，单位是毫秒
       lastTimestamp = timestamp;

       // 这儿就是最核心的二进制位运算操作，生成一个64bit的id
       // 先将当前时间戳左移，放到41 bit那儿；将机房id左移放到5 bit那儿；将机器id左移放到5 bit那儿；将序号放最后12 bit
       // 最后拼接起来成一个64 bit的二进制数字，转换成10进制就是个long型
       return ((timestamp - twepoch) << timestampLeftShift) |
               (datacenterId << datacenterIdShift) |
               (workerId << workerIdShift) | sequence;
   }

   private long tilNextMillis(long lastTimestamp) {
       
       long timestamp = timeGen();
       
       while (timestamp <= lastTimestamp) {
           timestamp = timeGen();
       }
       return timestamp;
   }

   private long timeGen(){
       return System.currentTimeMillis();
   }

   //---------------测试---------------
   public static void main(String[] args) {
       
       IdWorker worker = new IdWorker(1,1,1);
       
       for (int i = 0; i < 30; i++) {
           System.out.println(worker.nextId());
       }
   }
}
```

#### 雪花算法改进思路

- 很多时候，机房并没有那么多，所以那 5 个 bit 用做机房id可能意义不是太大，这几位可以变成具体业务的 id。
- 可以根据系统的体量和实际情况调整后面时间戳之后的位数对应的含义，调整最大的 id 数。

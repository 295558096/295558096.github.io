# 架构笔记

## 并发系列

### volatile

#### 工作内存与主内存

- 每个线程都有自己的工作内存用来存放`变量的副本`。
- `工作内存`相当于一个高速的本地缓存。
- CPU执行代码指令的时候，如果频繁从主内存加载数据，**性能**会比较差。
- 多个线程并发读写一个共享变量的时候，有可能某个线程修改了变量的值，但是其他线程不可见。

#### 作用

1. `volatile`修饰的变量，当本地工作内存修改了值之后，会**强制刷新**结果回主内存，保证主内存和本地内存的数据一致性。
2. 如果此时别的线程的工作内存中有这个变量的本地缓存，会强制让**其他线程**的工作内存中的**变量缓存直接失效过期**，不允许再次读取和使用了。
3. 当另一个线程要读取本地工作内存中被修改过的值，会发现数据已经过期。线程会从主内存中加载变量的最新的值。

#### 总结

- volatile主要作用是保证**可见性**以及**有序性**。
- 有序性涉及到**指令重排**、**内存屏障**等概念。
- volatile不能保证**原子性**。

### Java8对CAS性能的优化

#### 问题场景

- 对于一个变量信息累加的操作，不加锁的正常情况下会出现并发问题。
- 使用`synchronized`的锁量级过重。

#### Atomic原子类的底层原理

- Atomic 原子类底层用的不是传统意义的锁机制，而是无锁化的**CAS机制**，通过 CAS 机制保证多线程修改一个数值的安全性。
- CAS，`Compare and Set`，先比较再进行设置。
- 当如果在执行 CAS 的时候，发现之前获取的值跟当前的值不一样，会导致 CAS 失败，失败之后，进入一个无限循环，再次获取值，接着执行 CAS 操作。

#### Java8对CAS机制的优化

- 在大量线程高并发更新原子类的时候，可能会导致大量线程空循环、自转，**性能和效率**都不是特别好。
- `LongAdder`，通过尝试使用**分段CAS**以及**自动分段迁移**的方式来大幅度提升多线程高并发执行CAS操作的性能。

##### LongAdder

- 在 LongAdder 的底层实现中，首先有个 base 值，刚开始多线程来不停的累加数值，都是对 base 进行累加的。
- 接着如果发现并发更新的线程数量过多，就会开始施行分段 CAS 的机制，也就是内部会搞 Cell 数组，每个数组是一个数值分段。
- 大量的线程分别去对不同 Cell 内部的 value 值进行 CAS 累加操作，这样就把 CAS 计算压力分散到了不同的 Cell 分段数值中，降低了 CAS 计算压力。
- 如果要从 LongAdder 中获取当前累加的总值，就会把 base 值和所有 Cell 分段数值加起来返回给你。
- `自动分段迁移` 如果某个 Cell 的 value 执行 CAS 失败了，那么就会自动去找另外一个 Cell 分段内的 value 值进行 CAS 操作。解決了线程空旋转、自旋不停等待执行 CAS 操作的问题，让一个线程过来执行 CAS 时可以尽快的完成这个操作。

##### 总结

- **高并发中的分段处理机制实际上是一个很常见和常用的并发优化手段。**

------

### Java 锁的一些概念

#### 公平锁

- 在出现多线程竞争锁的情况下，锁的分配严格按照线程请求锁时间的先后依次调度，这样的锁实现，称为公平锁。
- 锁的效率略低。
- 每个新来请求锁资源的线程不会直接进行 CAS 操作去获取锁，而且判断当前等候队列是否存在等待线程。如果存在等待线程，当前线程会直接插入队尾。

#### 非公平锁

- 在出现多线程竞争锁的情况下，请求锁的线程可以直接通过 CAS 操作去申请锁资源，锁的分配不严格按照线程请求锁时间的先后依次调度，这样的锁实现，称为非公平锁。
- 效率高于公平锁。
- 每个新来请求锁资源的线程都会进行 CAS 加锁操作，可能出现插队成功现象，锁的利用率更高。
- **java 并发包中很多锁的默认行为都是非公平锁。**

#### 重入锁

- 当一个线程持有锁的时候，可以访问任意需要该锁的资源和方法。
- ReentrantLock、ReentrantReadWriteLock都是可重入锁的实现。
- 发生锁的重入行为时，`AQS#state`的值 + 1。
- 释放锁的时候，`AQS#state`递减，直到 `state=0`，设置 owner 为 null。

#### 非重入锁

- 锁不可以被任意线程重复持有，获取锁的 CAS 操作的预期 state 值始终为 0。
- 由于不可重入，释放锁的时候，直接设置 `state=0`、`owner=null`。
- `NonReentrantLock` 是不可重入锁的实现。

### AQS 的理解

#### AQS 简介

- Java 高并发的基石。
- 全称 `AbstractQueuedSynchronizer`，抽象队列同步器。
- Java 并发包下很多 API 都是包含了 AQS 的一种实现，都是基于 AQS 实现了加锁、释放锁等功能。
- ReentrantLock、ReentrantReadWriteLock 底层都是基于 AQS。

#### ReentrantLock 底层原理

##### AQS 核心变量

- `state`
  - int 类型。
  - 表示加锁的状态。
  - 初始状态下 state 的值是 0。
- `exclusiveOwnerThread`
  - Thread 类型。
  - 用来记录当前加锁线程是哪个线程。
  - 初始化状态下，这个变量是 null。
- `head`、`tail`
  - 都是 Node 类型。
  - 属性包含 `next` 和 `prev`  指向前一个和后一个 Node 对象。
  - 相当于维护在 AQS 内部的一个等待队列，存储加锁失败的线程。

##### 加锁过程

- 通过 CAS 修改 `AQS#state` 的值为 1。
- CAS 修改成功说明锁未被占用，则更新 `exclusiveOwnerThread` 为当前线程。
- CAS 修改失败说明锁已经被占用，将当前线程封装为 `Node` 添加到等候队列的队尾，并完成线程自挂起`Thread.currentThread().interrupt()`操作。

##### 释放锁过程

- 通过比较 `exclusiveOwnerThread`和当前线程，判断当前线程是否持有当前锁，如果未持有锁，抛出 `IllegalMonitorStateException` 异常。
- 如果当前线程持有锁，`AQS#state` 进行减一操作，当 `AQS#state` 为 0，设置 `exclusiveOwnerThread` 为 null 并唤醒等待队列队列头的线程。
- 释放锁成功，唤醒等候线程队列对头的线程进行 CAS 加锁操作，**如果是非公平锁，此时被唤醒的头部线程未必一定可以获得到锁，可能被外来的线程直接抢到锁**。

------

### 微服务注册中心的读写锁优化

#### 读写锁

- 所谓的读写锁，就是将一个锁拆分为**读锁**和**写锁**两个锁。
- 加锁的时候，可以选择加写锁，也可以选择加读锁。
- **加读锁的操作是不受影响的，可以多个线程同时申请到读锁。**
- 当一个线程加了写锁，那么其他线程就不能加写锁了，**同一时间只能允许一个线程加写锁**。
- **当一个线程加了写锁，其他线程就不能加读锁**。
- **如果任意一个线程加了读锁，此时其他线程是不可以加写锁的**，写入操作需要等待读锁完全被释放。
- **读写锁是非常适合读多写少的场景的。**

#### 服务注册表

- 注册中心会维护一张服务注册表，用来存储服务及服务实例端口、服务地址等数据。
- 由于注册中心的业务场景特点，在内存中的服务注册表天然存在读写并发问题，可能存在同时多线程读、多线程写的问题。

#### 优化流程

##### synchronized

- 简单粗暴的给读写方法都添加上 `synchronized` 关键字。
- 虽然能达到数据的读写安全，但是并发性能很低，并不推荐。

##### 读写锁

- 通过使用读写锁，保证读写业务的安全和高效。
- 服务注册表的业务场景，大部分时候都是读操作，所以使用**读锁**可以让大量的线程同时来读数据，**不需要阻塞不需要排队，保证高并发读的性能是比较高的**。
- 服务注册表的业务场景，**存在少量的写入场景，使用写锁**，保证写入数据过程中，不会存在**并发修改数据**或者**读取数据**的问题。

##### 多级缓存

- 通过**多级缓存**的机制，尽量在写数据的期间还保证可以继续读数据，同时在大量加读锁的时候，降低阻塞写数据加写锁过长时间的情况。

------

### 重要数据的双缓冲区+异步刷盘方案

#### 背景

- 重要核心的业务数据持久化的降级方案。
- 数据正常会以消息的方式发送的 MQ 集群中，由于 MQ 天然的抗高并发性，不需要额外的性能优化设计。
- 为了保证重要的业务数据不丢失，需要对 MQ 集群故障设计一套降级的解决方案。

#### 方案

- 当 MQ 集群故障后，使用**内存双缓冲区+异步刷盘**方案进行业务数据的本地化存储的方案。

- 内存中双缓存区分为 ready 区、current 区。
  - ready 区域中数据是即将要进行刷入本地磁盘文件的数据。
  - current 区域是用来存储来自于当前系统请求中业务数据。
  - ready 区域在每次刷盘后清空内容。
  - 当 current 区域中的数据达到额定容量且 ready 区域为空的时候，交换分区。如果 ready 区域正在进行刷盘操作，不为空时候，系统会挂起后续的写入请求。
- 异步刷盘使用Java NIO 的 API，高性能 append 方式的写入到本地磁盘文件。
- 本地磁盘文件也有自己的文件大小限制、文件新建策略。

#### 流程图

![双缓冲区+异步刷盘](README-image/%E5%8F%8C%E7%BC%93%E5%86%B2%E5%8C%BA+%E5%BC%82%E6%AD%A5%E5%88%B7%E7%9B%98.png)

#### 并发优化

- 双缓冲区的默认值是 512K，可以通过简单的性能测试，
- 线上生产环境出现极高并发的时候，本地刷盘需要一定的时候，导致缓冲区不能释放，大量线程挂起阻塞，造成系统无响应。
- 解决方案是调整缓冲区的大小，从 512K 调整到 10MB。

------



### RabbitMQ 消息生产者的可靠投递

#### 场景

- 消息在投递的过程中，由于网络问题出现丢失。
- 消息被接收后，在消息中间件的内存中没有写入磁盘就产生了宕机。

#### 解决方案

- 生产者端开启 `confirm` 模式，通过 ack 确认消息已经正常的完成投递和持久化，否则根据业务需要进行重新投递。
- 在收到 MQ 回传的 ack 之前，要缓存消息的内容，便于重新投递。
- 开启了`confirm` 模式之后，每次消息投递也同样是有一个 `delivery tag` 的，也是起到**唯一标识一次消息投递**的作用。
- Rabbit MQ接收消息后，如果产生内部错误，会通过 `nack` 通过生产者，生产者根据 nack 返回的内容进行投递失败处理。
- 如果某条消息很长时间都没有回传 `ack/nack`，那可能是极端意外情况发生数据产生丢失，可以进行重新投递。

#### confirm机制投递消息的高延迟性

- 一旦启用了`confirm` 机制投递消息到MQ之后，MQ是不保证什么时候会给你一个 `ack` 或者 `nack` 的。
- RabbitMQ采用异步批量刷盘的方式将消息批量从内存持久化到硬盘的方式兼顾了高并发写入的吞吐量和性能的方案。因此，在开启了 `confirm` 机制后，`ack` 或者 `nack` 消息可能出现延迟。
- 如果采用每条消息都强制刷盘操作的话，会大大降低集群的吞吐量，不建议 `fsync`。

#### 问题分析

##### 消息缓存介质的选择

- 等待 `ack/nack` 期间，缓存的消息不建议使用内存，高并发场景下，可能因为缓存过多的消息而导致内存溢出。
- KV 存储是理想的选择，kV 存储承载高并发能力极强，且 KV 操作性能很高，推荐 Redis 等。

##### 写消息方式的选择

- 绝对不能以**同步写消息 + 等待ack的方式**来投递，那样会导致每次投递一个消息都同步阻塞等待几百毫秒，会导致投递性能和吞吐量大幅度下降。
- **投递消息之后等待 ack 的过程必须是异步的。**消息投递出去之后，投递线程就可以正常返回，每个消息的异步回调，是通过在 `channel` 注册一个 `confirmListener` 实现的。
  - 收到一个消息 ack 后，就从 KV 存储中删除这条临时消息。
  - 收到一个消息 nack 后，就从 KV 存储提取消息重新投递。
  - 通过对 KV 存储里的消息做监控，过滤出超过一定时长没收到 ack的消息，进行主动重发。

#### 消息中间件全链路的数据可靠要点

##### 保证生产端投递出去的消息不丢失

- 避免消息在半路丢失。
- 避免消息在 MQ 内存中因为宕机等原因丢失。
- 结合不同的 MQ 提供的 API 保证数据的可靠性。

##### 保证MQ自身消息不丢失

- 开启持久化功能，将消息写入到磁盘中。
- 使用镜像集群，备份多套消息数据。

##### 保证消费端的消费消息不丢失

- 关闭自动 ack，开始手动 ack 机制。

------

### Java 并发性能优化的一些建议

#### 双缓冲机制

- 解决中间件系统、大数据系统经常需要涉及的场景就是**核心数据写入磁盘**的核心数据缓存问题。
- 在内存中开辟两块空间，向其中一块缓冲器内写数据，当这块缓冲区满额后，后来的写入操作转移到另一块缓冲区。当前缓冲区开始进行异步的刷盘操作。
- 通过两块缓冲区交替缓存、刷盘的工作方式，提供系统的并发性能。

#### 内存缓冲区分片机制+分段加锁机制

- xxx







